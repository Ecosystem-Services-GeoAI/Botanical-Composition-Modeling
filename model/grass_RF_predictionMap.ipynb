{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2503747-0cca-407e-9290-c59f053042cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03fa13f-01d1-420e-afc8-23cac5094fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/changzhao/zhou.tang/conda/envs/soc_gpu/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/blue/changzhao/zhou.tang/conda/envs/soc_gpu/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define index calculation functions\n",
    "def calculate_savi(red, nir, L=0.5):\n",
    "    return ((nir - red) * (1 + L)) / (nir + red + L)\n",
    "\n",
    "def calculate_ndvi(red, nir):\n",
    "    return (nir - red) / (nir + red)\n",
    "\n",
    "def calculate_vari(green, red, blue):\n",
    "    return (green - red) / (green + red - blue)\n",
    "\n",
    "def calculate_exg(green, red, blue):\n",
    "    return 2 * green - red - blue\n",
    "\n",
    "def calculate_ndre(nir, red_edge):\n",
    "    return (nir - red_edge) / (nir + red_edge)\n",
    "\n",
    "# model_weight = \"/blue/changzhao/zhou.tang/botanical_composition/data/bc_rf_model_20241104.joblib\"\n",
    "model_weight = \"/blue/changzhao/zhou.tang/botanical_composition/data/bc_rf_model_20241105_allData.joblib\"\n",
    "rf_model = joblib.load(model_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd73156-059b-4bcc-a03d-0b22c4fc4705",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/49290172/ipykernel_3008085/3439913320.py:6: RuntimeWarning: invalid value encountered in divide\n",
      "  return (nir - red) / (nir + red)\n",
      "/scratch/local/49290172/ipykernel_3008085/3439913320.py:9: RuntimeWarning: divide by zero encountered in divide\n",
      "  return (green - red) / (green + red - blue)\n",
      "/scratch/local/49290172/ipykernel_3008085/3439913320.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  return (green - red) / (green + red - blue)\n",
      "/scratch/local/49290172/ipykernel_3008085/3439913320.py:15: RuntimeWarning: invalid value encountered in divide\n",
      "  return (nir - red_edge) / (nir + red_edge)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack features\n",
      "features shape is (28914, 16933, 11)\n",
      "savi_mask_flat shape is (489600762,)\n",
      "features_reshaped shape is (489600762, 11)\n",
      "combined_mask shape is (489600762,)\n",
      "start predict from 0 to 10000000\n",
      "start predict from 10000000 to 20000000\n",
      "start predict from 20000000 to 30000000\n",
      "start predict from 30000000 to 40000000\n",
      "start predict from 40000000 to 50000000\n",
      "start predict from 50000000 to 60000000\n",
      "start predict from 60000000 to 70000000\n",
      "start predict from 70000000 to 80000000\n",
      "start predict from 80000000 to 90000000\n",
      "start predict from 90000000 to 100000000\n",
      "start predict from 100000000 to 110000000\n",
      "start predict from 110000000 to 120000000\n",
      "start predict from 120000000 to 130000000\n",
      "start predict from 130000000 to 140000000\n",
      "start predict from 140000000 to 150000000\n",
      "start predict from 150000000 to 160000000\n",
      "start predict from 160000000 to 170000000\n",
      "start predict from 170000000 to 180000000\n",
      "start predict from 180000000 to 190000000\n",
      "start predict from 190000000 to 200000000\n",
      "start predict from 200000000 to 210000000\n",
      "start predict from 210000000 to 220000000\n",
      "start predict from 220000000 to 230000000\n",
      "start predict from 230000000 to 240000000\n",
      "start predict from 240000000 to 250000000\n",
      "start predict from 250000000 to 260000000\n",
      "start predict from 260000000 to 270000000\n",
      "start predict from 270000000 to 280000000\n",
      "start predict from 280000000 to 290000000\n",
      "start predict from 290000000 to 300000000\n",
      "start predict from 300000000 to 310000000\n",
      "start predict from 310000000 to 320000000\n",
      "start predict from 320000000 to 330000000\n",
      "start predict from 330000000 to 340000000\n",
      "start predict from 340000000 to 350000000\n",
      "start predict from 350000000 to 360000000\n",
      "start predict from 360000000 to 370000000\n",
      "start predict from 370000000 to 380000000\n",
      "start predict from 380000000 to 390000000\n",
      "start predict from 390000000 to 400000000\n",
      "start predict from 400000000 to 410000000\n",
      "start predict from 410000000 to 420000000\n",
      "start predict from 420000000 to 428055462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/changzhao/zhou.tang/conda/envs/soc_gpu/lib/python3.8/site-packages/numpy/core/_asarray.py:130: RuntimeWarning: invalid value encountered in cast\n",
      "  arr = array(a, dtype=dtype, order=order, copy=False, subok=subok)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction TIFF has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "tiff_src = \"/blue/changzhao/zhou.tang/botanical_composition/data/All_Paddock_26_JUL_2024_ortho_bgrent.tiff\"\n",
    "# tiff_src = \"/blue/changzhao/zhou.tang/botanical_composition/data/All_Paddock_22_SEP_2024_ortho_bgrent.tiff\"\n",
    "output_tiff_name = \"/blue/changzhao/zhou.tang/botanical_composition/data/predictionmap_July_20241105.tiff\"\n",
    "chunk_size = 10000000\n",
    "# Read the multi-band TIFF\n",
    "with rasterio.open(tiff_src) as src:\n",
    "    band_1_b = src.read(1)\n",
    "    band_2_g = src.read(2)\n",
    "    band_3_r = src.read(3)\n",
    "    band_4_rd = src.read(4)\n",
    "    band_5_nir = src.read(5)\n",
    "    band_6_lwir = src.read(6)  # If needed for other analysis\n",
    "\n",
    "# Calculate the indices\n",
    "SAVI = calculate_savi(band_3_r, band_5_nir)\n",
    "NDVI = calculate_ndvi(band_3_r, band_5_nir)\n",
    "VARI = calculate_vari(band_2_g, band_3_r, band_1_b)\n",
    "ExG = calculate_exg(band_2_g, band_3_r, band_1_b)\n",
    "NDRE = calculate_ndre(band_5_nir, band_4_rd)\n",
    "# savi_mask = SAVI > 0.9 # used for 20241104 prediction map\n",
    "savi_mask = SAVI > 0.6   # used for 20241105 prediction map\n",
    "\n",
    "print(\"stack features\")\n",
    "# Prepare the features for prediction\n",
    "# Assume the model expects a 2D array with specific feature order, e.g., [SAVI, NDVI, VARI, EXG, NDRE]\n",
    "features = np.stack([band_1_b, band_2_g, band_3_r, band_4_rd, band_5_nir, band_6_lwir, SAVI, NDVI, VARI, ExG, NDRE], axis=-1)\n",
    "\n",
    "# Replace inf/-inf with NaN\n",
    "features[np.isinf(features)] = np.nan\n",
    "# Clip values to a reasonable range (optional, adjust as needed)\n",
    "features = np.clip(features, -1e6, 1e6)\n",
    "print(f\"features shape is {features.shape}\")\n",
    "\n",
    "# Flatten the SAVI mask and feature array for consistent indexing\n",
    "savi_mask_flat = savi_mask.flatten()\n",
    "print(f\"savi_mask_flat shape is {savi_mask_flat.shape}\")\n",
    "# Reshape the features array to be 2D: (num_pixels, num_features)\n",
    "features_reshaped = features.reshape(-1, features.shape[-1])\n",
    "print(f\"features_reshaped shape is {features_reshaped.shape}\")\n",
    "# Filter out NaN values from features array\n",
    "# Create a mask where none of the feature values are NaN or inf\n",
    "valid_mask = ~np.isnan(features_reshaped).any(axis=1) & ~np.isinf(features_reshaped).any(axis=1)\n",
    "# Combine valid_mask with the SAVI condition\n",
    "combined_mask = savi_mask_flat & valid_mask\n",
    "print(f\"combined_mask shape is {combined_mask.shape}\")\n",
    "\n",
    "# Apply the combined mask to filter out invalid rows\n",
    "features_valid = features_reshaped[combined_mask]\n",
    "# Convert to DataFrame with appropriate feature names for prediction\n",
    "feature_names = [\"band_1_b\", \"band_2_g\", \"band_3_r\", \"band_4_rd\", \"band_5_nir\", \"band_6_lwir\", \"SAVI\", \"NDVI\", \"VARI\", \"ExG\", \"NDRE\"]\n",
    "features_valid_df = pd.DataFrame(features_valid, columns=feature_names)\n",
    "\n",
    "\n",
    "# Split the valid features into chunks for processing\n",
    "num_pixels = features_valid_df.shape[0]\n",
    "num_chunks = (num_pixels // chunk_size) + 1 \n",
    "\n",
    "# Create an empty array for storing prediction results\n",
    "output_array = np.full(SAVI.shape, np.nan)\n",
    "output_array_flat = output_array.flatten()\n",
    "\n",
    "predictions_flat = np.full(features_valid_df.shape[0], np.nan)\n",
    "\n",
    "class_mapping = {\n",
    "    'grass': 1,\n",
    "    'legume': 2\n",
    "    # Add other classes as needed\n",
    "}\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    # Get start and end indices for the current chunk\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min(start_idx + chunk_size, num_pixels)\n",
    "    \n",
    "    # Extract the current chunk of features and mask\n",
    "    features_chunk_df = features_valid_df.iloc[start_idx:end_idx,:]\n",
    "    print(f\"start predict from {start_idx} to {end_idx}\")\n",
    "\n",
    "    if features_chunk_df.size > 0:\n",
    "\n",
    "        # Make predictions on the current chunk\n",
    "        predictions_chunk = rf_model.predict(features_chunk_df)\n",
    "        # print(predictions_chunk)\n",
    "        predictions_chunk_mapped = np.array([class_mapping[pred] for pred in predictions_chunk])\n",
    "        # print(predictions_chunk_mapped)\n",
    "        # Assign predictions to the corresponding positions in the flattened output array\n",
    "        predictions_flat[start_idx:end_idx] = predictions_chunk_mapped\n",
    "\n",
    "        \n",
    "output_array_flat[combined_mask] = predictions_flat\n",
    "# Reshape the output array back to the original image shape\n",
    "output_array = output_array_flat.reshape(SAVI.shape)\n",
    "\n",
    "# Save the predictions as a new TIFF\n",
    "with rasterio.open(\n",
    "    output_tiff_name,\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=src.height,\n",
    "    width=src.width,\n",
    "    count=1,\n",
    "    dtype='int32',\n",
    "    crs=src.crs,\n",
    "    transform=src.transform,\n",
    ") as dst:\n",
    "    dst.write(output_array, 1)\n",
    "\n",
    "print(\"Prediction TIFF has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2af2c1-51f7-4270-b743-dad35772a94e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savi_mask_flat shape is (489600762,)\n",
      "features_reshaped shape is (489600762, 11)\n",
      "combined_mask shape is (489600762,)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the SAVI mask and feature array for consistent indexing\n",
    "savi_mask_flat = savi_mask.flatten()\n",
    "print(f\"savi_mask_flat shape is {savi_mask_flat.shape}\")\n",
    "# Reshape the features array to be 2D: (num_pixels, num_features)\n",
    "features_reshaped = features.reshape(-1, features.shape[-1])\n",
    "print(f\"features_reshaped shape is {features_reshaped.shape}\")\n",
    "# Filter out NaN values from features array\n",
    "# Create a mask where none of the feature values are NaN or inf\n",
    "valid_mask = ~np.isnan(features_reshaped).any(axis=1) & ~np.isinf(features_reshaped).any(axis=1)\n",
    "# Combine valid_mask with the SAVI condition\n",
    "combined_mask = savi_mask_flat & valid_mask\n",
    "print(f\"combined_mask shape is {combined_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6f680c-1d60-4f81-b2a4-6096f95a3c44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412550134\n"
     ]
    }
   ],
   "source": [
    "# Apply the combined mask to filter out invalid rows\n",
    "features_valid = features_reshaped[combined_mask]\n",
    "\n",
    "# Convert to DataFrame with appropriate feature names for prediction\n",
    "feature_names = [\"band_1_b\", \"band_2_g\", \"band_3_r\", \"band_4_rd\", \"band_5_nir\", \"band_6_lwir\", \"SAVI\", \"NDVI\", \"VARI\", \"ExG\", \"NDRE\"]\n",
    "features_valid_df = pd.DataFrame(features_valid, columns=feature_names)\n",
    "\n",
    "print(features_valid_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13d75797-cae7-425e-aad5-0f91f926a1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predict from 0 to 1000000\n",
      "start predict from 1000000 to 2000000\n",
      "start predict from 2000000 to 3000000\n",
      "start predict from 3000000 to 4000000\n",
      "start predict from 4000000 to 5000000\n",
      "start predict from 5000000 to 6000000\n",
      "start predict from 6000000 to 7000000\n",
      "start predict from 7000000 to 8000000\n",
      "start predict from 8000000 to 9000000\n",
      "start predict from 9000000 to 10000000\n",
      "start predict from 10000000 to 11000000\n",
      "start predict from 11000000 to 12000000\n",
      "start predict from 12000000 to 13000000\n",
      "start predict from 13000000 to 14000000\n",
      "start predict from 14000000 to 15000000\n",
      "start predict from 15000000 to 16000000\n",
      "start predict from 16000000 to 17000000\n",
      "start predict from 17000000 to 18000000\n",
      "start predict from 18000000 to 19000000\n",
      "start predict from 19000000 to 20000000\n",
      "start predict from 20000000 to 21000000\n",
      "start predict from 21000000 to 22000000\n",
      "start predict from 22000000 to 23000000\n",
      "start predict from 23000000 to 24000000\n",
      "start predict from 24000000 to 25000000\n",
      "start predict from 25000000 to 26000000\n",
      "start predict from 26000000 to 27000000\n",
      "start predict from 27000000 to 28000000\n",
      "start predict from 28000000 to 29000000\n",
      "start predict from 29000000 to 30000000\n",
      "start predict from 30000000 to 31000000\n",
      "start predict from 31000000 to 32000000\n",
      "start predict from 32000000 to 33000000\n",
      "start predict from 33000000 to 34000000\n",
      "start predict from 34000000 to 35000000\n",
      "start predict from 35000000 to 36000000\n",
      "start predict from 36000000 to 37000000\n",
      "start predict from 37000000 to 38000000\n",
      "start predict from 38000000 to 39000000\n",
      "start predict from 39000000 to 40000000\n",
      "start predict from 40000000 to 41000000\n",
      "start predict from 41000000 to 42000000\n",
      "start predict from 42000000 to 43000000\n",
      "start predict from 43000000 to 44000000\n",
      "start predict from 44000000 to 45000000\n",
      "start predict from 45000000 to 46000000\n",
      "start predict from 46000000 to 47000000\n",
      "start predict from 47000000 to 48000000\n",
      "start predict from 48000000 to 49000000\n",
      "start predict from 49000000 to 50000000\n",
      "start predict from 50000000 to 51000000\n",
      "start predict from 51000000 to 52000000\n",
      "start predict from 52000000 to 53000000\n",
      "start predict from 53000000 to 54000000\n",
      "start predict from 54000000 to 55000000\n",
      "start predict from 55000000 to 56000000\n",
      "start predict from 56000000 to 57000000\n",
      "start predict from 57000000 to 58000000\n",
      "start predict from 58000000 to 59000000\n",
      "start predict from 59000000 to 60000000\n",
      "start predict from 60000000 to 61000000\n",
      "start predict from 61000000 to 62000000\n",
      "start predict from 62000000 to 63000000\n",
      "start predict from 63000000 to 64000000\n",
      "start predict from 64000000 to 65000000\n",
      "start predict from 65000000 to 66000000\n",
      "start predict from 66000000 to 67000000\n",
      "start predict from 67000000 to 68000000\n",
      "start predict from 68000000 to 69000000\n",
      "start predict from 69000000 to 70000000\n",
      "start predict from 70000000 to 71000000\n",
      "start predict from 71000000 to 72000000\n",
      "start predict from 72000000 to 73000000\n",
      "start predict from 73000000 to 74000000\n",
      "start predict from 74000000 to 75000000\n",
      "start predict from 75000000 to 76000000\n",
      "start predict from 76000000 to 77000000\n",
      "start predict from 77000000 to 78000000\n",
      "start predict from 78000000 to 79000000\n",
      "start predict from 79000000 to 80000000\n",
      "start predict from 80000000 to 81000000\n",
      "start predict from 81000000 to 82000000\n",
      "start predict from 82000000 to 83000000\n",
      "start predict from 83000000 to 84000000\n",
      "start predict from 84000000 to 85000000\n",
      "start predict from 85000000 to 86000000\n",
      "start predict from 86000000 to 87000000\n",
      "start predict from 87000000 to 88000000\n",
      "start predict from 88000000 to 89000000\n",
      "start predict from 89000000 to 90000000\n",
      "start predict from 90000000 to 91000000\n",
      "start predict from 91000000 to 92000000\n",
      "start predict from 92000000 to 93000000\n",
      "start predict from 93000000 to 94000000\n",
      "start predict from 94000000 to 95000000\n",
      "start predict from 95000000 to 96000000\n",
      "start predict from 96000000 to 97000000\n",
      "start predict from 97000000 to 98000000\n",
      "start predict from 98000000 to 99000000\n",
      "start predict from 99000000 to 100000000\n",
      "start predict from 100000000 to 101000000\n",
      "start predict from 101000000 to 102000000\n",
      "start predict from 102000000 to 103000000\n",
      "start predict from 103000000 to 104000000\n",
      "start predict from 104000000 to 105000000\n",
      "start predict from 105000000 to 106000000\n",
      "start predict from 106000000 to 107000000\n",
      "start predict from 107000000 to 108000000\n",
      "start predict from 108000000 to 109000000\n",
      "start predict from 109000000 to 110000000\n",
      "start predict from 110000000 to 111000000\n",
      "start predict from 111000000 to 112000000\n",
      "start predict from 112000000 to 113000000\n",
      "start predict from 113000000 to 114000000\n",
      "start predict from 114000000 to 115000000\n",
      "start predict from 115000000 to 116000000\n",
      "start predict from 116000000 to 117000000\n",
      "start predict from 117000000 to 118000000\n",
      "start predict from 118000000 to 119000000\n",
      "start predict from 119000000 to 120000000\n",
      "start predict from 120000000 to 121000000\n",
      "start predict from 121000000 to 122000000\n",
      "start predict from 122000000 to 123000000\n",
      "start predict from 123000000 to 124000000\n",
      "start predict from 124000000 to 125000000\n",
      "start predict from 125000000 to 126000000\n",
      "start predict from 126000000 to 127000000\n",
      "start predict from 127000000 to 128000000\n",
      "start predict from 128000000 to 129000000\n",
      "start predict from 129000000 to 130000000\n",
      "start predict from 130000000 to 131000000\n",
      "start predict from 131000000 to 132000000\n",
      "start predict from 132000000 to 133000000\n",
      "start predict from 133000000 to 134000000\n",
      "start predict from 134000000 to 135000000\n",
      "start predict from 135000000 to 136000000\n",
      "start predict from 136000000 to 137000000\n",
      "start predict from 137000000 to 138000000\n",
      "start predict from 138000000 to 139000000\n",
      "start predict from 139000000 to 140000000\n",
      "start predict from 140000000 to 141000000\n",
      "start predict from 141000000 to 142000000\n",
      "start predict from 142000000 to 143000000\n",
      "start predict from 143000000 to 144000000\n",
      "start predict from 144000000 to 145000000\n",
      "start predict from 145000000 to 146000000\n",
      "start predict from 146000000 to 147000000\n",
      "start predict from 147000000 to 148000000\n",
      "start predict from 148000000 to 149000000\n",
      "start predict from 149000000 to 150000000\n",
      "start predict from 150000000 to 151000000\n",
      "start predict from 151000000 to 152000000\n",
      "start predict from 152000000 to 153000000\n",
      "start predict from 153000000 to 154000000\n",
      "start predict from 154000000 to 155000000\n",
      "start predict from 155000000 to 156000000\n",
      "start predict from 156000000 to 157000000\n",
      "start predict from 157000000 to 158000000\n",
      "start predict from 158000000 to 159000000\n",
      "start predict from 159000000 to 160000000\n",
      "start predict from 160000000 to 161000000\n",
      "start predict from 161000000 to 162000000\n",
      "start predict from 162000000 to 163000000\n",
      "start predict from 163000000 to 164000000\n",
      "start predict from 164000000 to 165000000\n",
      "start predict from 165000000 to 166000000\n",
      "start predict from 166000000 to 167000000\n",
      "start predict from 167000000 to 168000000\n",
      "start predict from 168000000 to 169000000\n",
      "start predict from 169000000 to 170000000\n",
      "start predict from 170000000 to 171000000\n",
      "start predict from 171000000 to 172000000\n",
      "start predict from 172000000 to 173000000\n",
      "start predict from 173000000 to 174000000\n",
      "start predict from 174000000 to 175000000\n",
      "start predict from 175000000 to 176000000\n",
      "start predict from 176000000 to 177000000\n",
      "start predict from 177000000 to 178000000\n",
      "start predict from 178000000 to 179000000\n",
      "start predict from 179000000 to 180000000\n",
      "start predict from 180000000 to 181000000\n",
      "start predict from 181000000 to 182000000\n",
      "start predict from 182000000 to 183000000\n",
      "start predict from 183000000 to 184000000\n",
      "start predict from 184000000 to 185000000\n",
      "start predict from 185000000 to 186000000\n",
      "start predict from 186000000 to 187000000\n",
      "start predict from 187000000 to 188000000\n",
      "start predict from 188000000 to 189000000\n",
      "start predict from 189000000 to 190000000\n",
      "start predict from 190000000 to 191000000\n",
      "start predict from 191000000 to 192000000\n",
      "start predict from 192000000 to 193000000\n",
      "start predict from 193000000 to 194000000\n",
      "start predict from 194000000 to 195000000\n",
      "start predict from 195000000 to 196000000\n",
      "start predict from 196000000 to 197000000\n",
      "start predict from 197000000 to 198000000\n",
      "start predict from 198000000 to 199000000\n",
      "start predict from 199000000 to 200000000\n",
      "start predict from 200000000 to 201000000\n",
      "start predict from 201000000 to 202000000\n",
      "start predict from 202000000 to 203000000\n",
      "start predict from 203000000 to 204000000\n",
      "start predict from 204000000 to 205000000\n",
      "start predict from 205000000 to 206000000\n",
      "start predict from 206000000 to 207000000\n",
      "start predict from 207000000 to 208000000\n",
      "start predict from 208000000 to 209000000\n",
      "start predict from 209000000 to 210000000\n",
      "start predict from 210000000 to 211000000\n",
      "start predict from 211000000 to 212000000\n",
      "start predict from 212000000 to 213000000\n",
      "start predict from 213000000 to 214000000\n",
      "start predict from 214000000 to 215000000\n",
      "start predict from 215000000 to 216000000\n",
      "start predict from 216000000 to 217000000\n",
      "start predict from 217000000 to 218000000\n",
      "start predict from 218000000 to 219000000\n",
      "start predict from 219000000 to 220000000\n",
      "start predict from 220000000 to 221000000\n",
      "start predict from 221000000 to 222000000\n",
      "start predict from 222000000 to 223000000\n",
      "start predict from 223000000 to 224000000\n",
      "start predict from 224000000 to 225000000\n",
      "start predict from 225000000 to 226000000\n",
      "start predict from 226000000 to 227000000\n",
      "start predict from 227000000 to 228000000\n",
      "start predict from 228000000 to 229000000\n",
      "start predict from 229000000 to 230000000\n",
      "start predict from 230000000 to 231000000\n",
      "start predict from 231000000 to 232000000\n",
      "start predict from 232000000 to 233000000\n",
      "start predict from 233000000 to 234000000\n",
      "start predict from 234000000 to 235000000\n",
      "start predict from 235000000 to 236000000\n",
      "start predict from 236000000 to 237000000\n",
      "start predict from 237000000 to 238000000\n",
      "start predict from 238000000 to 239000000\n",
      "start predict from 239000000 to 240000000\n",
      "start predict from 240000000 to 241000000\n",
      "start predict from 241000000 to 242000000\n",
      "start predict from 242000000 to 243000000\n",
      "start predict from 243000000 to 244000000\n",
      "start predict from 244000000 to 245000000\n",
      "start predict from 245000000 to 246000000\n",
      "start predict from 246000000 to 247000000\n",
      "start predict from 247000000 to 248000000\n",
      "start predict from 248000000 to 249000000\n",
      "start predict from 249000000 to 250000000\n",
      "start predict from 250000000 to 251000000\n",
      "start predict from 251000000 to 252000000\n",
      "start predict from 252000000 to 253000000\n",
      "start predict from 253000000 to 254000000\n",
      "start predict from 254000000 to 255000000\n",
      "start predict from 255000000 to 256000000\n",
      "start predict from 256000000 to 257000000\n",
      "start predict from 257000000 to 258000000\n",
      "start predict from 258000000 to 259000000\n",
      "start predict from 259000000 to 260000000\n",
      "start predict from 260000000 to 261000000\n",
      "start predict from 261000000 to 262000000\n",
      "start predict from 262000000 to 263000000\n",
      "start predict from 263000000 to 264000000\n",
      "start predict from 264000000 to 265000000\n",
      "start predict from 265000000 to 266000000\n",
      "start predict from 266000000 to 267000000\n",
      "start predict from 267000000 to 268000000\n",
      "start predict from 268000000 to 269000000\n",
      "start predict from 269000000 to 270000000\n",
      "start predict from 270000000 to 271000000\n",
      "start predict from 271000000 to 272000000\n",
      "start predict from 272000000 to 273000000\n",
      "start predict from 273000000 to 274000000\n",
      "start predict from 274000000 to 275000000\n",
      "start predict from 275000000 to 276000000\n",
      "start predict from 276000000 to 277000000\n",
      "start predict from 277000000 to 278000000\n",
      "start predict from 278000000 to 279000000\n",
      "start predict from 279000000 to 280000000\n",
      "start predict from 280000000 to 281000000\n",
      "start predict from 281000000 to 282000000\n",
      "start predict from 282000000 to 283000000\n",
      "start predict from 283000000 to 284000000\n",
      "start predict from 284000000 to 285000000\n",
      "start predict from 285000000 to 286000000\n",
      "start predict from 286000000 to 287000000\n",
      "start predict from 287000000 to 288000000\n",
      "start predict from 288000000 to 289000000\n",
      "start predict from 289000000 to 290000000\n",
      "start predict from 290000000 to 291000000\n",
      "start predict from 291000000 to 292000000\n",
      "start predict from 292000000 to 293000000\n",
      "start predict from 293000000 to 294000000\n",
      "start predict from 294000000 to 295000000\n",
      "start predict from 295000000 to 296000000\n",
      "start predict from 296000000 to 297000000\n",
      "start predict from 297000000 to 298000000\n",
      "start predict from 298000000 to 299000000\n",
      "start predict from 299000000 to 300000000\n",
      "start predict from 300000000 to 301000000\n",
      "start predict from 301000000 to 302000000\n",
      "start predict from 302000000 to 303000000\n",
      "start predict from 303000000 to 304000000\n",
      "start predict from 304000000 to 305000000\n",
      "start predict from 305000000 to 306000000\n",
      "start predict from 306000000 to 307000000\n",
      "start predict from 307000000 to 308000000\n",
      "start predict from 308000000 to 309000000\n",
      "start predict from 309000000 to 310000000\n",
      "start predict from 310000000 to 311000000\n",
      "start predict from 311000000 to 312000000\n",
      "start predict from 312000000 to 313000000\n",
      "start predict from 313000000 to 314000000\n",
      "start predict from 314000000 to 315000000\n",
      "start predict from 315000000 to 316000000\n",
      "start predict from 316000000 to 317000000\n",
      "start predict from 317000000 to 318000000\n",
      "start predict from 318000000 to 319000000\n",
      "start predict from 319000000 to 320000000\n",
      "start predict from 320000000 to 321000000\n",
      "start predict from 321000000 to 322000000\n",
      "start predict from 322000000 to 323000000\n",
      "start predict from 323000000 to 324000000\n",
      "start predict from 324000000 to 325000000\n",
      "start predict from 325000000 to 326000000\n",
      "start predict from 326000000 to 327000000\n",
      "start predict from 327000000 to 328000000\n",
      "start predict from 328000000 to 329000000\n",
      "start predict from 329000000 to 330000000\n",
      "start predict from 330000000 to 331000000\n",
      "start predict from 331000000 to 332000000\n",
      "start predict from 332000000 to 333000000\n",
      "start predict from 333000000 to 334000000\n",
      "start predict from 334000000 to 335000000\n",
      "start predict from 335000000 to 336000000\n",
      "start predict from 336000000 to 337000000\n",
      "start predict from 337000000 to 338000000\n",
      "start predict from 338000000 to 339000000\n",
      "start predict from 339000000 to 340000000\n",
      "start predict from 340000000 to 341000000\n",
      "start predict from 341000000 to 342000000\n",
      "start predict from 342000000 to 343000000\n",
      "start predict from 343000000 to 344000000\n",
      "start predict from 344000000 to 345000000\n",
      "start predict from 345000000 to 346000000\n",
      "start predict from 346000000 to 347000000\n",
      "start predict from 347000000 to 348000000\n",
      "start predict from 348000000 to 349000000\n",
      "start predict from 349000000 to 350000000\n",
      "start predict from 350000000 to 351000000\n",
      "start predict from 351000000 to 352000000\n",
      "start predict from 352000000 to 353000000\n",
      "start predict from 353000000 to 354000000\n",
      "start predict from 354000000 to 355000000\n",
      "start predict from 355000000 to 356000000\n",
      "start predict from 356000000 to 357000000\n",
      "start predict from 357000000 to 358000000\n",
      "start predict from 358000000 to 359000000\n",
      "start predict from 359000000 to 360000000\n",
      "start predict from 360000000 to 361000000\n",
      "start predict from 361000000 to 362000000\n",
      "start predict from 362000000 to 363000000\n",
      "start predict from 363000000 to 364000000\n",
      "start predict from 364000000 to 365000000\n",
      "start predict from 365000000 to 366000000\n",
      "start predict from 366000000 to 367000000\n",
      "start predict from 367000000 to 368000000\n",
      "start predict from 368000000 to 369000000\n",
      "start predict from 369000000 to 370000000\n",
      "start predict from 370000000 to 371000000\n",
      "start predict from 371000000 to 372000000\n",
      "start predict from 372000000 to 373000000\n",
      "start predict from 373000000 to 374000000\n",
      "start predict from 374000000 to 375000000\n",
      "start predict from 375000000 to 376000000\n",
      "start predict from 376000000 to 377000000\n",
      "start predict from 377000000 to 378000000\n",
      "start predict from 378000000 to 379000000\n",
      "start predict from 379000000 to 380000000\n",
      "start predict from 380000000 to 381000000\n",
      "start predict from 381000000 to 382000000\n",
      "start predict from 382000000 to 383000000\n",
      "start predict from 383000000 to 384000000\n",
      "start predict from 384000000 to 385000000\n",
      "start predict from 385000000 to 386000000\n",
      "start predict from 386000000 to 387000000\n",
      "start predict from 387000000 to 388000000\n",
      "start predict from 388000000 to 389000000\n",
      "start predict from 389000000 to 390000000\n",
      "start predict from 390000000 to 391000000\n",
      "start predict from 391000000 to 392000000\n",
      "start predict from 392000000 to 393000000\n",
      "start predict from 393000000 to 394000000\n",
      "start predict from 394000000 to 395000000\n",
      "start predict from 395000000 to 396000000\n",
      "start predict from 396000000 to 397000000\n",
      "start predict from 397000000 to 398000000\n",
      "start predict from 398000000 to 399000000\n",
      "start predict from 399000000 to 400000000\n",
      "start predict from 400000000 to 401000000\n",
      "start predict from 401000000 to 402000000\n",
      "start predict from 402000000 to 403000000\n",
      "start predict from 403000000 to 404000000\n",
      "start predict from 404000000 to 405000000\n",
      "start predict from 405000000 to 406000000\n",
      "start predict from 406000000 to 407000000\n",
      "start predict from 407000000 to 408000000\n",
      "start predict from 408000000 to 409000000\n",
      "start predict from 409000000 to 410000000\n",
      "start predict from 410000000 to 411000000\n",
      "start predict from 411000000 to 412000000\n",
      "start predict from 412000000 to 412550134\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid dtype: dtype('O')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m output_array \u001b[38;5;241m=\u001b[39m output_array_flat\u001b[38;5;241m.\u001b[39mreshape(SAVI\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Save the predictions as a new TIFF\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mrasterio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_predictions.tiff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGTiff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions_chunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m dst:\n\u001b[1;32m     55\u001b[0m     dst\u001b[38;5;241m.\u001b[39mwrite(output_array, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction TIFF has been saved successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/blue/changzhao/zhou.tang/conda/envs/soc_gpu/lib/python3.8/site-packages/rasterio/env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    448\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/changzhao/zhou.tang/conda/envs/soc_gpu/lib/python3.8/site-packages/rasterio/__init__.py:222\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid driver: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(driver))\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_dtype(dtype):\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid dtype: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dtype))\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nodata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     nodata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(nodata)\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid dtype: dtype('O')"
     ]
    }
   ],
   "source": [
    "chunk_size = 1000000\n",
    "# Split the valid features into chunks for processing\n",
    "num_pixels = features_valid_df.shape[0]\n",
    "num_chunks = (num_pixels // chunk_size) + 1 \n",
    "\n",
    "# Create an empty array for storing prediction results\n",
    "output_array = np.full(SAVI.shape, np.nan, dtype='float32')\n",
    "output_array_flat = output_array.flatten()\n",
    "\n",
    "predictions_flat = np.full(features_valid_df.shape[0], np.nan)\n",
    "\n",
    "\n",
    "class_mapping = {\n",
    "    'grass': 1,\n",
    "    'legume': 2\n",
    "    # Add other classes as needed\n",
    "}\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    # Get start and end indices for the current chunk\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min(start_idx + chunk_size, num_pixels)\n",
    "    \n",
    "    # Extract the current chunk of features and mask\n",
    "    features_chunk_df = features_valid_df.iloc[start_idx:end_idx,:]\n",
    "    print(f\"start predict from {start_idx} to {end_idx}\")\n",
    "\n",
    "    if features_chunk_df.size > 0:\n",
    "\n",
    "        # Make predictions on the current chunk\n",
    "        predictions_chunk = rf_model.predict(features_chunk_df)\n",
    "        # print(predictions_chunk)\n",
    "        predictions_chunk_mapped = np.array([class_mapping[pred] for pred in predictions_chunk])\n",
    "        # print(predictions_chunk_mapped)\n",
    "        # Assign predictions to the corresponding positions in the flattened output array\n",
    "        predictions_flat[start_idx:end_idx] = predictions_chunk_mapped\n",
    "\n",
    "        \n",
    "output_array_flat[combined_mask] = predictions_flat\n",
    "# Reshape the output array back to the original image shape\n",
    "output_array = output_array_flat.reshape(SAVI.shape)\n",
    "\n",
    "# Save the predictions as a new TIFF\n",
    "with rasterio.open(\n",
    "    'output_predictions.tiff',\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=src.height,\n",
    "    width=src.width,\n",
    "    count=1,\n",
    "    dtype='int32',\n",
    "    crs=src.crs,\n",
    "    transform=src.transform,\n",
    ") as dst:\n",
    "    dst.write(output_array, 1)\n",
    "\n",
    "print(\"Prediction TIFF has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8906a520-c033-4472-a38d-c6ec31a551c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/changzhao/zhou.tang/conda/envs/soc_gpu/lib/python3.8/site-packages/numpy/core/_asarray.py:130: RuntimeWarning: invalid value encountered in cast\n",
      "  arr = array(a, dtype=dtype, order=order, copy=False, subok=subok)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction TIFF has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the predictions as a new TIFF\n",
    "with rasterio.open(\n",
    "    'output_predictions.tiff',\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=src.height,\n",
    "    width=src.width,\n",
    "    count=1,\n",
    "    dtype='int32',\n",
    "    crs=src.crs,\n",
    "    transform=src.transform,\n",
    ") as dst:\n",
    "    dst.write(output_array, 1)\n",
    "\n",
    "print(\"Prediction TIFF has been saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soc_gpu",
   "language": "python",
   "name": "soc_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
